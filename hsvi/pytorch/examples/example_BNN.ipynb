{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from hsvi.pytorch import Hierarchy_SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "from torch.distributions import Normal, OneHotCategorical\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor,Lambda,Compose\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayesian_Linear(nn.Module):\n",
    "    def __init__(self,d1,d2,bias=True):\n",
    "        super(Bayesian_Linear, self).__init__()\n",
    "        self.bias = bias\n",
    "        self.w_loc = torch.normal(torch.zeros([d1,d2]),torch.ones([d1,d2])*0.001)\n",
    "        self.w_loc = Parameter(self.w_loc)\n",
    "        self.w_logv = torch.ones([d1,d2])*-3\n",
    "        self.w_logv = Parameter(self.w_logv)\n",
    "        self.w = Normal(self.w_loc,torch.exp(self.w_logv))\n",
    "        self.w_prior = Normal(loc=torch.zeros([d1,d2]),scale=torch.ones([d1,d2])) \n",
    "        \n",
    "        if bias:\n",
    "            self.b_loc = torch.normal(torch.zeros([d2]),torch.ones([d2])*0.001)\n",
    "            self.b_loc = Parameter(self.b_loc)\n",
    "            self.b_logv = torch.ones([d2])*-3\n",
    "            self.b_logv = Parameter(self.b_logv)\n",
    "            self.b = Normal(self.b_loc,torch.exp(self.b_logv))\n",
    "            self.b_prior = Normal(loc=torch.zeros([d2]),scale=torch.ones([d2]))\n",
    "            \n",
    "    def forward(self,x):\n",
    "        h = torch.matmul(x,self.w.rsample())\n",
    "        if self.bias:\n",
    "            h += self.b.rsample()\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayesian_MLP(nn.Module):\n",
    "    def __init__(self,net_shape,ac_fn=nn.ReLU):\n",
    "        super(Bayesian_MLP, self).__init__()\n",
    "        self.net_shape = net_shape\n",
    "        self.ac_fn = ac_fn\n",
    "        self.net = self._build_net()\n",
    "    \n",
    "    def _build_net(self):\n",
    "        modules = []\n",
    "        for i in range(len(self.net_shape)-1):\n",
    "            print('conf layer {}'.format(i))\n",
    "            d1 = self.net_shape[i]\n",
    "            d2 = self.net_shape[i+1]\n",
    "            modules.append(Bayesian_Linear(d1,d2))\n",
    "            if i != len(net_shape) - 2:\n",
    "                modules.append(self.ac_fn())\n",
    "        return nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_inference(model,TRAIN_SIZE,vi_type='KLqp',learning_rate=0.001,scale=1.):\n",
    "    \n",
    "    \n",
    "    ### config variational inference ###\n",
    "    inference = Hierarchy_SVI(vi_types={'global':vi_type},var_dict={'global':model.parameters()},learning_rate={'global':0.001},train_size=TRAIN_SIZE,scale={'global':{}})        \n",
    "\n",
    "\n",
    "    return inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 50000\n",
    "test_size = 10000\n",
    "batch_size = 256\n",
    "epoch = 50\n",
    "hidden = [100,100]\n",
    "use_cuda = False\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN = datasets.MNIST(\n",
    "    root=\"/home/yu/gits/data/mnist/\",\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=Compose([ToTensor(), Lambda(lambda x: torch.flatten(x))]),\n",
    "    #target_transform=Compose([\n",
    "    #                              lambda x:torch.LongTensor([x]), \n",
    "    #                                lambda x:F.one_hot(x,10)])\n",
    ")\n",
    "indices = torch.arange(train_size)\n",
    "X_TRAIN = Subset(X_TRAIN, indices)\n",
    "\n",
    "X_TEST = datasets.MNIST(\n",
    "    root=\"/home/yu/gits/data/mnist/\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=Compose([ToTensor(), Lambda(lambda x: torch.flatten(x))]),\n",
    "    #target_transform=Compose([\n",
    "    #                             lambda x:torch.LongTensor([x]), \n",
    "    #                             lambda x:F.one_hot(x,10)])\n",
    ")\n",
    "indices = torch.arange(test_size)\n",
    "X_TEST = Subset(X_TEST, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(X_TRAIN, batch_size=batch_size, shuffle=True,num_workers=8)\n",
    "test_dataloader = DataLoader(X_TEST, batch_size=batch_size, shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### config net shape ###\n",
    "d_dim = 784\n",
    "out_dim = 10\n",
    "net_shape = [d_dim] + hidden + [out_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf layer 0\n",
      "conf layer 1\n",
      "conf layer 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bayesian_MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Bayesian_Linear()\n",
       "    (1): ReLU()\n",
       "    (2): Bayesian_Linear()\n",
       "    (3): ReLU()\n",
       "    (4): Bayesian_Linear()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Bayesian_MLP(net_shape)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqz = {}\n",
    "for module in model.modules():\n",
    "    if isinstance(module,Bayesian_Linear):\n",
    "        pqz.update({module.w_prior:module.w,module.b_prior:module.b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start init hsvi\n",
      "global KLqp\n"
     ]
    }
   ],
   "source": [
    "inference = config_inference(model,train_size,learning_rate=lr,vi_type='KLqp')\n",
    "inference.latent_vars = {'global':pqz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/gits/p36env/lib/python3.6/site-packages/torch/autograd/__init__.py:149: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 loss 4.550666332244873\n",
      "epoch 20 loss 4.528886318206787\n",
      "epoch 30 loss 4.500082969665527\n",
      "epoch 40 loss 4.497791767120361\n",
      "epoch 50 loss 4.5003461837768555\n"
     ]
    }
   ],
   "source": [
    "### training process ###\n",
    "\n",
    "for e in range(epoch):\n",
    "    \n",
    "    for i,(x_batch,y_batch) in enumerate(train_dataloader): \n",
    "        x_batch.to(device)\n",
    "        y_batch.to(device)\n",
    "        \n",
    "        ### use to compute the liklihood of raw data ###        \n",
    "        ll = F.cross_entropy(model(x_batch),y_batch) \n",
    "        \n",
    "        inference.data = {'global':{}}\n",
    "        inference.extra_loss = {'global':ll}\n",
    "\n",
    "        loss = inference.update('global',retain_graph=True)\n",
    "    if (e+1)%10==0:\n",
    "        print('epoch {} loss {}'.format(e+1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.9747999906539917\n"
     ]
    }
   ],
   "source": [
    "### test process ###\n",
    "correct = 0\n",
    "for i,(x_batch,y_batch) in enumerate(test_dataloader): \n",
    "    x_batch.to(device)\n",
    "    y_batch.to(device)\n",
    "    py = torch.argmax(model(x_batch),1)\n",
    "    #print((py==y_batch).sum())\n",
    "    #correct += (py==y_batch).sum()\n",
    "    correct += (py==y_batch).sum()\n",
    "acc = correct/test_size\n",
    "print('accuracy is {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36env",
   "language": "python",
   "name": "p36env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
